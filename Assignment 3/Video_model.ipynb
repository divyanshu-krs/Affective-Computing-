{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "97wNh1A-uUlg",
        "colab_type": "code",
        "outputId": "e996dde0-b79b-4aa1-a0c2-156cee2595b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5jzF-OnvDjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import glob\n",
        "from time import time\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.utils import Sequence\n",
        "from keras.models import Sequential, Model \n",
        "from keras import layers\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntcLa3LzvbYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/drive/My Drive/Affective Computing/Assn_3/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKWr88M1vzaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the model\n",
        "def emotion_recognition_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(120,224,224,3)))\n",
        "  model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "  model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "  model.add(Conv3D(96, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "  model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "  model.add(Conv3D(256, kernel_size=(3, 3, 3), activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(2048, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(7, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRG3gzXNv4hp",
        "colab_type": "code",
        "outputId": "f04cdc76-f4dd-4922-e510-954fe20431b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "model = emotion_recognition_model()\n",
        "model.summary() "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d_1 (Conv3D)            (None, 118, 222, 222, 32) 2624      \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 59, 111, 111, 32)  0         \n",
            "_________________________________________________________________\n",
            "conv3d_2 (Conv3D)            (None, 57, 109, 109, 64)  55360     \n",
            "_________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3 (None, 28, 54, 54, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_3 (Conv3D)            (None, 26, 52, 52, 96)    165984    \n",
            "_________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3 (None, 13, 26, 26, 96)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_4 (Conv3D)            (None, 11, 24, 24, 128)   331904    \n",
            "_________________________________________________________________\n",
            "max_pooling3d_4 (MaxPooling3 (None, 5, 12, 12, 128)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_5 (Conv3D)            (None, 3, 10, 10, 256)    884992    \n",
            "_________________________________________________________________\n",
            "max_pooling3d_5 (MaxPooling3 (None, 1, 5, 5, 256)      0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2048)              13109248  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 14343     \n",
            "=================================================================\n",
            "Total params: 14,564,455\n",
            "Trainable params: 14,564,455\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJWGmEHWv95U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class for inputing data batch by batch\n",
        "#Not generalized enough works only for batch size 1 as of now i.e. (1,120,224,224,3) which is required for doing 3D convolution and detect optical flow to determine a given action\n",
        "class MY_Generator(Sequence):\n",
        "    def __init__(self, video_filenames, video_gt, batch_size):\n",
        "        self.video_filenames, self.video_gt = video_filenames, video_gt\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_filenames) \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.video_filenames[idx:idx+self.batch_size]\n",
        "        batch_y = self.video_gt[idx:idx+self.batch_size]\n",
        "        x = load_img(batch_x[0])\n",
        "        x = img_to_array(x)\n",
        "        video = np.zeros((self.batch_size,120,224,224,3))\n",
        "        # y = cv2.imread(batch_y[0])\n",
        "        for i in range(self.batch_size):\n",
        "          for j in range(120):\n",
        "            video[i,j,:,:,:] = x[224*j:224*(j+1),:,:]\n",
        "        video /= 255 \n",
        "        label = batch_y[0]\n",
        "        gt = np.zeros((self.batch_size,7))\n",
        "        for i in range(self.batch_size):\n",
        "          if label == 'happy':\n",
        "            gt[i,:] = [0,0,0,0,0,0,0]\n",
        "          elif label == 'sad':\n",
        "            gt[i,:] = [1,0,0,0,0,0,0]\n",
        "          elif label == 'disgust':\n",
        "            gt[i,:] = [0,1,0,0,0,0,0]\n",
        "          elif label == 'angry':\n",
        "            gt[i,:] = [0,0,1,0,0,0,0]\n",
        "          elif label == 'surprised':\n",
        "            gt[i,: ] = [0,0,0,1,0,0,0]\n",
        "          elif label == 'calm':\n",
        "            gt[i,:] = [0,0,0,0,1,0,0]\n",
        "          elif  label == 'neutral':\n",
        "            gt[i,:] = [0,0,0,0,0,1,0]\n",
        "          else:\n",
        "            gt[i,:] = [0,0,0,0,0,0,1]\n",
        "        # print(image,gt)\n",
        "        return video,gt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRAY_Gn5wKu4",
        "colab_type": "code",
        "outputId": "5c99e13e-c0f5-40af-b545-c7f682195304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "def main():\n",
        "  \n",
        "  model = emotion_recognition_model()\n",
        "  adam = keras.optimizers.Adam(lr=0.001)\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy, optimizer=adam, metrics=['accuracy'])\n",
        "  csv_file = pd.read_csv(path+'train_label.csv')\n",
        "  z = csv_file.iloc[:,0].values\n",
        "  gt = csv_file.iloc[:,1].values\n",
        "  #print(z.head())\n",
        "  print(z.shape)\n",
        "  final_index = len(glob.glob(path+'data_preprocessing/*'))\n",
        "  print(final_index)\n",
        "\n",
        "  csv_test_file = pd.read_csv(path+'test_label.csv')\n",
        "  test_z = csv_test_file.iloc[:,0].values\n",
        "  gt_test = csv_test_file.iloc[:,1].values\n",
        "  #print(z.head())\n",
        " # print(z.shape)\n",
        "  test_final_index = len(glob.glob(path+'test_data_proc/*'))\n",
        "\n",
        "\n",
        "  # print(final_index)\n",
        "  initial_index = 1\n",
        "  # final_index = 10\n",
        "  #print(final_index)\n",
        "  train_video_filenames = []\n",
        "  train_video_filenames[:] = z[:]\n",
        "  # print(train_video_filenames)\n",
        "  train_video_ground_truth = []\n",
        "  train_video_ground_truth = gt[:]\n",
        "  for i in range(len(train_video_filenames)):\n",
        "    train_video_filenames[i] = path + train_video_filenames[i][2:]\n",
        "  \n",
        "\n",
        "  validate_video_filenames = []\n",
        "  validate_video_filenames[:] = test_z[:]\n",
        "  for i in range(len(validate_video_filenames)):\n",
        "    validate_video_filenames[i] = path + validate_video_filenames[i][2:]\n",
        "\n",
        "  validate_video_ground_truth = []\n",
        "  validate_video_ground_truth = gt_test[:]\n",
        "\n",
        "  #creating my_generator objects\n",
        "  batch_size = 1\n",
        "  my_training_batch_generator = MY_Generator(train_video_filenames,train_video_ground_truth, batch_size)\n",
        "  my_validation_batch_generator = MY_Generator(validate_video_filenames, validate_video_ground_truth, batch_size)\n",
        "\n",
        "\n",
        "  # os.mkdir(path+'checkpoints')\n",
        "  # os.mkdir(path+'logs')\n",
        "  checkpoint_path = path+\"checkpoints/cp-1.ckpt\"\n",
        "  cp_callback = keras.callbacks.ModelCheckpoint(checkpoint_path,monitor='val_loss',\n",
        "     verbose=1, save_best_only=True,\n",
        "     mode = 'min')\n",
        "  tensorboard = TensorBoard(log_dir=path+\"logs/{}\".format(time()))  \n",
        "  #training started\n",
        "  model.fit_generator(generator=my_training_batch_generator,\n",
        "                                         steps_per_epoch=(len(train_video_filenames)),\n",
        "                                         epochs=6,\n",
        "                                         verbose=1,\n",
        "                                         validation_data=my_validation_batch_generator,\n",
        "                                         validation_steps=(len(validate_video_filenames)),\n",
        "                                         callbacks=[tensorboard,cp_callback])\n",
        "  print(\"successfully finished training!!!\")\n",
        "\n",
        "main()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2400,)\n",
            "2400\n",
            "Epoch 1/6\n",
            "2400/2400 [==============================] - 3688s 2s/step - loss: 1.7808 - accuracy: 0.1704 - val_loss: 2.2420 - val_accuracy: 0.1333\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.24201, saving model to /content/drive/My Drive/Affective Computing/Assn_3/checkpoints/cp-1.ckpt\n",
            "Epoch 2/6\n",
            "2400/2400 [==============================] - 1452s 605ms/step - loss: 1.9328 - accuracy: 0.1492 - val_loss: 1.4523 - val_accuracy: 0.1333\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.24201 to 1.45229, saving model to /content/drive/My Drive/Affective Computing/Assn_3/checkpoints/cp-1.ckpt\n",
            "Epoch 3/6\n",
            "2400/2400 [==============================] - 1448s 603ms/step - loss: 2.1151 - accuracy: 0.1663 - val_loss: 3.5250 - val_accuracy: 0.2667\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.45229\n",
            "Epoch 4/6\n",
            "2400/2400 [==============================] - 1443s 601ms/step - loss: 2.3513 - accuracy: 0.1513 - val_loss: 2.8661 - val_accuracy: 0.1333\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.45229\n",
            "Epoch 5/6\n",
            "2400/2400 [==============================] - 1454s 606ms/step - loss: 2.5112 - accuracy: 0.1425 - val_loss: 3.3929 - val_accuracy: 0.1333\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.45229\n",
            "Epoch 6/6\n",
            "2400/2400 [==============================] - 1454s 606ms/step - loss: 2.6163 - accuracy: 0.1475 - val_loss: 4.4522 - val_accuracy: 0.1333\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.45229\n",
            "successfully finished training!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-6-bwMv1Arp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "8d1f8df2-fe1c-4944-af8c-54eeb828a95a"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2400\n",
            "2400\n",
            "480\n",
            "480\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}